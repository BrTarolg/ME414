---
title: "Exercise 9 - Topic Models"
author: "Jack Blumenau, Ken Benoit & Slava Mikhaylov"
output: html_document
---

You will need to load the following libraries (you may also want to set the random number seed to make everything replicable):
```{r, eval=T, message = F}
library(quanteda)
library(topicmodels)
library(LDAvis)
library(stm)
library(knitr)
library(lda)
set.seed(221186)
```

## Exercise 9.1

In this question we are going to use topic modelling to understand how parliamentary speech varies by the gender of the MP. We will be working with a corpus of speeches made by legislators in the UK House of Commons in the 2014 calandar year. You will need to make sure that the file `hoc_speeches.Rdata` is in your current working directory, and then use the following command to read this data into `R`.


```{r, message = FALSE}

load("hoc_speeches.Rdata")

```
 
 (a) Inspect the `data.frame` object `speeches` and produce some summary statistics.

```{r}

prop.table(table(speeches$party, speeches$gender),1)

speeches$ntoken <- ntoken(speeches$speech)
hist(speeches$ntoken, main = "Distribution of speech length", breaks = 100)

```

 (a) Use the functions in the `quanteda` package to turn this data into a `corpus` object. Attach the relevant metadata as `docvars`.

```{r}

speechCorpus <- corpus(speeches$speech, docvars = speeches)

```

 (b) Turn this corpus into a document-feature matrix. You will need to do some pre-processing if you don't want to wait days for your topic model to coverge. Think about some of the following:
 
    (i) Unigrams? 
    (ii) Stopwords?
    (iii) Stemming?
    (iv) Very infrequent words?

```{r, message = FALSE}

speechDFM <- dfm(speechCorpus, ignoredFeatures = stopwords("SMART"), stem = T)

speechDFM <- trim(speechDFM, minCount = 5, minDoc = 0.0025)

```

 (c) Run a structural topic model for this corpus, using the `gender` variable in the topic prevalence argument. Use the `stm` function to do this (remember to convert your `dfm` for use with the stm package). Set the `seed` argument to `stm` to be equal to `123`. Be aware, this takes about 15 minutes to run on Jack's laptop -- for testing purposes you might want to set the maximum iterations for the stm to be some low number (`max.em.its = 10` for instance).

First, `convert` the `speechDFM` to the `stm` format using Ken's cool function:

```{r}

stmTexts <- convert(speechDFM, to = "stm", docvars = docvars(speechCorpus))

```

Now specify and estimate the `stm` model:

```{r, cache = T, message=FALSE}

K <- 20
stmOut <- stm(documents = stmTexts$documents, 
              vocab = stmTexts$vocab, 
              data = stmTexts$meta,
              prevalence = ~gender,
              K, seed = 123, verbose = FALSE)

```

Plot the estimated topic model:

```{r}
plot(stmOut)
```

  (d) Examine the top words from each topic

```{r}

topic_labels <- labelTopics(stmOut)
topic_labels <- apply(topic_labels$prob,1, function(x) paste(x, collapse=";"))
print(topic_labels)
```


  (e) Find the top three documents associated with each topic. Do these make sense given the words you have used to describe that topic? (Hint: in the estimated `stm` object, the document-topic probabilities are stored in `theta`) Report the top speeches for one selected topic.
  
```{r}

top_docs <- apply(stmOut$theta, 2, function(x) order(x, decreasing = T)[1:3])

top_school_docs <- top_docs[,grep("school",topic_labels)]

stmTexts$meta[top_school_docs,"speech"]

```

  (f) Use the `estimateEffect` and `plot.estimateEffect` functions in the `stm` package to estimate the effect of MP gender on topic usage. On which topics are women, on average, more active? 

```{r}

est_gender_effect <- estimateEffect(~gender, stmOut, metadata = stmTexts$meta)

plot.estimateEffect(est_gender_effect, "gender", method = "difference", 
                    cov.value1 = "female", cov.value2 = "male", 
                    labeltype = "frex", n = 3, verbose.labels = F,
                    model = stmOut)

```

**Women appear to speak more about the `women,world,eu`, and `health,nhs,hospit` topics, though the significance of these is effects in this data is questionable.**

2.  **movies corpus**.  Here we will use the very impressive `LDAvis` library in conjunction with the `lda::lda.collapsed.gibbs.sampler()` function from the `lda` package. The following code is used to demonstate how the parliamentary speeches interactive visualisation example was created for in the lecture. Your task is to implement this for the `movies` corpus.

First we construct the relevant `dfm` and estimate the `lda` model.
```{r, eval=FALSE}
library(quanteda)
## Create a corpus of speeches
speechCorpus <- corpus(speeches$speech)

## Convert to dfm, removing some words that appear very regularly
speechDfm <- dfm(speechCorpus, ignoredFeatures = c(stopwords("SMART"),stopwords("english"), "will", "hon", "right","people","government","can","friend","house","gentleman","said", "interruption", "prime", "minister", "secretary", "state"), stem = F)

## Trim some rarely occuring words
speechDfm <- trim(speechDfm, minCount = 15, minDoc = .0015)

# Convert to lda format
speechDfmlda <- convert(speechDfm, to = "lda")
length(speechDfmlda[[1]])

# MCMC and model tuning parameters:
K <- 30 # Number of topics
G <- 2000 # Number of iterations
alpha <- 0.02 # Prior for topic proportions
eta <- 0.02 # Prior for topic distributions

# Fit the model
t1 <- Sys.time() # Start timer

fit <- lda.collapsed.gibbs.sampler(documents = speechDfmlda$documents, K = K, 
                                       vocab = speechDfmlda$vocab, 
                                      num.iterations = G, alpha = alpha, 
                                     eta = eta, initial = NULL, burnin = 0,
                                      compute.log.likelihood = TRUE)
        t2 <- Sys.time() # End timer
        t2 - t1  # about 15 minutes on Jack's MacBook Pro
```

Now we plot the model using `LDAvis`.

```{r, eval=FALSE}
library(LDAvis)
# create the JSON object to feed the visualization:
json <- createJSON(phi = t(apply(t(fit$topics) + eta, 2, function(x) x/sum(x))), 
                   theta = t(apply(fit$document_sums + alpha, 2, function(x) x/sum(x))), 
                   doc.length = ntoken(speechDfm), 
                   vocab = features(speechDfm), 
                   term.frequency = colSums(speechDfm))
        serVis(json, out.dir = "exampleVis", open.browser = TRUE)
```

  a.  You will need to load the data from the `quanteda` package: 
    
```{r}
data(movies, package = "quantedaData")
```
    
  b.  Adapt the code above to produce an interactive visualisation of the `movies` corpus. 
    
```{r, cache = TRUE, eval = FALSE}

        # prepare the texts
        moviesDfm <- dfm(movies, ignoredFeatures = stopwords("SMART"), stem = FALSE)
        moviesDfm <- trim(moviesDfm, minCount = 5)
        moviesDfm
        
        # MCMC and model tuning parameters:
        K <- 20
        G <- 3000
        alpha <- 0.02
        eta <- 0.02
        
        # convert to lda format
        moviesDfmlda <- convert(moviesDfm, to = "lda")
        # fit the model
        library(lda)
        set.seed(357)
        t1 <- Sys.time()
        fit <- lda.collapsed.gibbs.sampler(documents = moviesDfmlda$documents, K = K, 
                                           vocab = moviesDfmlda$vocab, 
                                           num.iterations = G, alpha = alpha, 
                                           eta = eta, initial = NULL, burnin = 0,
                                           compute.log.likelihood = TRUE)
        t2 <- Sys.time()
        t2 - t1  # about 10 minutes on Jack's iMac

        library(LDAvis)
        # create the JSON object to feed the visualization:
        json <- createJSON(phi = t(apply(t(fit$topics) + eta, 2, function(x) x/sum(x))), 
                           theta = t(apply(fit$document_sums + alpha, 2, function(x) x/sum(x))), 
                           doc.length = ntoken(moviesDfm), 
                           vocab = features(moviesDfm), 
                           term.frequency = colSums(moviesDfm))
        serVis(json, out.dir = "visColl", open.browser = TRUE)

```
    
  d.  Describe a few topics as you see them.  Is there a "scary movie" topic?  Is there a "science fiction" topic?  Figure out how to convert the interactive plot into a static figure, and include these in your answer.
    
    ![](LDAvis.png)  